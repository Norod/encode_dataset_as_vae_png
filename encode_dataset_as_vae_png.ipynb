{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMQbFgAw3WUnoC3vXhkvT0a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Norod/encode_dataset_as_vae_png/blob/main/encode_dataset_as_vae_png.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "famFYRadahKR"
      },
      "outputs": [],
      "source": [
        "!pip install transformers diffusers==0.2.4 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "2wCE1dFJawso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/Norod/encode_dataset_as_vae_png.git\n",
        "%cd ./encode_dataset_as_vae_png"
      ],
      "metadata": {
        "id": "nTxgBLEqa688"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from diffusers import AutoencoderKL\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torchvision import transforms as tfms\n",
        "import sys\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import csv \n",
        "from PIL.PngImagePlugin import PngInfo\n",
        "\n",
        "\n",
        "torch_device = None\n",
        "vae = None\n",
        "to_tensor_tfm = None\n",
        "\n",
        "csv_header = ['imageFile', 'minLatentVal', 'maxLatentVal']\n",
        "\n",
        "def setup():\n",
        "    global torch_device\n",
        "    global vae \n",
        "    global to_tensor_tfm \n",
        "\n",
        "    # Set device\n",
        "    torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Load the autoencoder model which will be used to decode the latents into image space. \n",
        "    vae = AutoencoderKL.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"vae\", use_auth_token=True)\n",
        "\n",
        "    # To the GPU we go!\n",
        "    vae = vae.to(torch_device)\n",
        "\n",
        "    # Using torchvision.transforms.ToTensor\n",
        "    to_tensor_tfm = tfms.ToTensor()\n",
        "\n",
        "def pil_to_latent(input_im):\n",
        "  # Single image -> single latent in a batch (so size 1, 4, 64, 64)\n",
        "  with torch.no_grad():\n",
        "    latent = vae.encode(to_tensor_tfm(input_im).unsqueeze(0).to(torch_device)*2-1) # Note scaling\n",
        "  return 0.18215 * latent.sample() # or .mean or .sample\n",
        "\n",
        "def latents_to_pil(latents):\n",
        "  # bath of latents -> list of images\n",
        "  latents = (1 / 0.18215) * latents\n",
        "  latents = latents.to(torch_device)\n",
        "  with torch.no_grad():\n",
        "    image = vae.decode(latents)\n",
        "  image = (image.detach().cpu() / 2 + 0.5).clamp(0, 1)\n",
        "  image = image.permute(0, 2, 3, 1).numpy()\n",
        "  images = (image * 255).round().astype(\"uint8\")\n",
        "  pil_images = [Image.fromarray(image) for image in images]\n",
        "  return pil_images\n",
        "\n",
        "def latents_as_images(latents):\n",
        "  minValue = latents.min()\n",
        "  maxValue = latents.max()\n",
        "  latents = (latents-minValue)/(maxValue-minValue)  \n",
        "  image = latents.detach().cpu().permute(0, 2, 3, 1).numpy()        \n",
        "  images = (image * 255).round().astype(\"uint8\")\n",
        "  pil_images = [Image.fromarray(image) for image in images]\n",
        "  minValue = minValue.detach().cpu().numpy().astype(\"float32\")\n",
        "  maxValue = maxValue.detach().cpu().numpy().astype(\"float32\")\n",
        "  return pil_images, str(minValue), str(maxValue)\n",
        "\n",
        "def encode(input_image_file):\n",
        "# Load the image with PIL\n",
        "    input_image = Image.open(input_image_file).resize((512, 512))\n",
        "    encoded = pil_to_latent(input_image)    \n",
        "    return encoded\n",
        "\n",
        "def decode(encoded_latents):\n",
        "    decoded = latents_to_pil(encoded_latents)[0]    \n",
        "    return decoded\n",
        "\n",
        "def is_float(value):\n",
        "  try:\n",
        "    float(value)\n",
        "    return True\n",
        "  except:\n",
        "    return False\n",
        "\n",
        "def reduced_latents_from_png(png_image_name):\n",
        "  image_in = Image.open(png_image_name)\n",
        "  image_text_data = image_in.text         #Check the PNG metadata for minValue, maxValue keys and load their value as float32 if possible\n",
        "  minValue = image_text_data[\"minValue\"]\n",
        "  if is_float(minValue):\n",
        "    minValue = float(minValue)\n",
        "  else:\n",
        "    minValue = float(-5.0)\n",
        "  maxValue = image_text_data[\"maxValue\"]\n",
        "  if is_float(maxValue):\n",
        "    maxValue = float(maxValue)\n",
        "  else:\n",
        "    maxValue = float(5.0)\n",
        "  image_in = np.array(image_in, np.float32)  \n",
        "  print(image_in.shape)\n",
        "  image_in = image_in/255.0\n",
        "  image_in = image_in.transpose((2, 0, 1))\n",
        "  image_out = np.expand_dims(image_in, 0)  \n",
        "  reduced_latents = torch.tensor(image_out)\n",
        "  reduced_latents = (reduced_latents*(maxValue-minValue))+minValue\n",
        "  print(reduced_latents.shape)\n",
        "  return reduced_latents\n",
        "\n",
        "def load_png_decode(input_file, output_file):\n",
        "  print(\"Load reduced latents\")\n",
        "  reduced_latents = reduced_latents_from_png(input_file)  \n",
        "  print(\"Decode reduced latents\")\n",
        "  image = decode(reduced_latents)\n",
        "  image.save(output_file)\n",
        "\n",
        "def encode_folder(input_folder, output_folder):\n",
        "  files = list(Path(input_folder).rglob(\"*.jpg\"))\n",
        "  csv_data = []\n",
        "  csv_data.append(csv_header)\n",
        "  for file in tqdm(files):\n",
        "    input_file = str(file)\n",
        "    output_file_name = str(file.stem) + \".png\"\n",
        "    output_file = output_folder + output_file_name\n",
        "    encoded_latents = encode(input_file)\n",
        "    encoded_latents_as_image, minValue, maxValue = latents_as_images(encoded_latents)\n",
        "    metadata = PngInfo()  #Write MinVale, MaxValue as part of the PNG metadata\n",
        "    metadata.add_itxt(\"minValue\", minValue)\n",
        "    metadata.add_itxt(\"maxValue\", maxValue)\n",
        "    encoded_latents_as_image[0].save(output_file, pnginfo=metadata)  #Note: The alpha channel also contains information\n",
        "    csv_data.append([output_file_name, minValue, maxValue]) #The generated CSV is not used in this sample, it is for reference only\n",
        "  \n",
        "  csv_file = output_folder + 'latentMinMaxValues.csv'\n",
        "  with open(csv_file, 'w', encoding='UTF8', newline=\"\\n\") as f:\n",
        "    writer = csv.writer(f)  \n",
        "    writer.writerows(csv_data)\n"
      ],
      "metadata": {
        "id": "0gbhQzGybAxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/encode_dataset_as_vae_png\n",
        "\n",
        "print(\"Load VAE\")\n",
        "setup()"
      ],
      "metadata": {
        "id": "JlaKRmpvbI8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Encode an example of a paired-image folders\")\n",
        "encode_folder(\"input/test_data/A/\", \"output/test_data/A/\")\n",
        "encode_folder(\"input/test_data/B/\", \"output/test_data/B/\")"
      ],
      "metadata": {
        "id": "_r7h39Y0bRdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Restore VAE latent from encapsulated PNGs and decode back the original image\")\n",
        "load_png_decode(\"output/test_data/A/seed40022.png\", \"out_seed40022_A_Val.png\")\n",
        "load_png_decode(\"output/test_data/B/seed40022.png\", \"out_seed40022_B_Val.png\")"
      ],
      "metadata": {
        "id": "cRfMSW1JbfUs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}